import requests
from bs4 import BeautifulSoup
import csv

# URL of GitHub Trending
url = "https://github.com/trending"

# Send GET request to GitHub Trending page
response = requests.get(url)
soup = BeautifulSoup(response.text, "html.parser")

# Find repository listings
repo_list = soup.find_all("article", class_="Box-row")[:5]  # Top 5

# Extract name and link
results = []
for repo in repo_list:
    anchor = repo.h2.a
    repo_name = anchor.text.strip().replace('\n', '').replace(' ', '')
    repo_link = "https://github.com" + anchor['href']
    results.append([repo_name, repo_link])

# Save to CSV
with open("trending_repos.csv", "w", newline="", encoding="utf-8") as file:
    writer = csv.writer(file)
    writer.writerow(["Repository Name", "Repository Link"])
    writer.writerows(results)

print("Top 5 trending repositories saved to trending_repos.csv")
